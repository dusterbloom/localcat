# Copy to server/.env and customize for your setup

#########################
# IDs & Models
#########################
USER_ID=dev-user
AGENT_ID=locat

# OpenAI-compatible API (Ollama default shown)
OPENAI_BASE_URL=http://127.0.0.1:11434/v1
OPENAI_API_KEY=not-needed
OPENAI_MODEL=gemma3:4b
# Enable Ollama "thinking" for conversation model (see https://ollama.com/blog/thinking)
OPENAI_THINK=false

# Optional embeddings model (unused by HotMem)
EMBEDDING_MODEL=

#########################
# Smart Turn / VAD
#########################
LOCAL_SMART_TURN_MODEL_PATH=/abs/path/to/smart-turn
ENABLE_MEMORY=true

#########################
# HotMem Storage & Logs
#########################
# Paths are resolved relative to server/; these point to repo-root data/
HOTMEM_SQLITE=../data/memory.db
HOTMEM_LMDB_DIR=../data/graph.lmdb

HOTMEM_LOG_FILE=server/.logs/hotmem.log
HOTMEM_CONSOLE_DEBUG=true
HOTMEM_LOG_LEVEL=DEBUG
HOTMEM_TRACE_FRAMES=false

# Injection formatting
HOTMEM_INJECT_ROLE=system
HOTMEM_INJECT_HEADER=Use the following factual context if helpful.
# Bullet cap per turn (1â€“5)
HOTMEM_BULLETS_MAX=5

#########################
# Session Summary & LEANN
#########################
SESSION_SUMMARY_ENABLED=true
REBUILD_LEANN_ON_SESSION_END=true

# Semantic retrieval (optional). Requires `pip install leann`.
HOTMEM_USE_LEANN=false
LEANN_INDEX_PATH=../data/memory_vectors.leann
LEANN_BACKEND=hnsw
HOTMEM_LEANN_COMPLEXITY=16

#########################
# Extraction Quality (Phase 2)
#########################
# Enable clause decomposition for complex sentences
HOTMEM_DECOMPOSE_CLAUSES=false
# Add conservative complexity-aware confidence scoring
HOTMEM_EXTRA_CONFIDENCE=false
# Minimum confidence required to store a fact
HOTMEM_CONFIDENCE_THRESHOLD=0.3

#########################
# Periodic Summarizer (LLM)
#########################
SUMMARIZER_ENABLED=true
SUMMARIZER_BASE_URL=http://127.0.0.1:1234/v1   # LM Studio default
SUMMARIZER_API_KEY=
SUMMARIZER_MODEL=qwen3:4b
SUMMARIZER_INTERVAL_SECS=30
SUMMARIZER_MAX_TOKENS=160

# Windowing: summarize new messages since last run (delta), or last N turn pairs
SUMMARIZER_WINDOW_MODE=delta   # delta | turn_pairs | tail
SUMMARIZER_TURN_PAIRS=2        # when WINDOW_MODE=turn_pairs
SUMMARIZER_MAX_MESSAGES=16
SUMMARIZER_INCLUDE_USER=true
SUMMARIZER_INCLUDE_ASSISTANT=true

# Reasoning controls for summarizer (best-effort)
# Set SUMMARIZER_THINK to true|false|low|medium|high (Ollama-compatible)
SUMMARIZER_THINK=
SUMMARIZER_REASONING_TOKENS=
SUMMARIZER_NUM_CTX=
